# -*- coding: utf-8 -*-
"""proyectoPLN3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ypMy51DmKO9yD4Ei3FOuLOF4MkY86LN5
"""

#!pip install pymupdf

import fitz  # PyMuPDF
import pandas as pd
import os
import requests

def color_to_rgb(color_int):
    r = (color_int >> 16) & 255
    g = (color_int >> 8) & 255
    b = color_int & 255
    return (r, g, b)

def descargar_pdf(fichero_pdf):
    # Cargar fichero PDF desde URL
    FileURL = url + fichero_pdf
    if not os.path.exists(fichero_pdf):
        response = requests.get(FileURL)
        # Verificamos que la solicitud fue exitosa
        if response.status_code == 200:
            # Abrimos el archivo PDF en modo de lectura binaria
            with open(FilePDF, 'wb') as file:
                file.write(response.content)
            #print("Archivo descargado y guardado localmente.")
        #else:
            #print(f"Error al descargar el archivo: {response.status_code}")

def extraer_informacion_pdf(fichero_pdf):
    # Abrir el PDF
    print("Fichero PDF procesado: " + fichero_pdf)
    doc = fitz.open(fichero_pdf)

    # Variables de contexto
    data = []
    familia_actual = ""
    grado_actual = ""
    codigo_ciclo = ""
    nombre_ciclo = ""
    provincia_actual = ""

    # Recorrer cada p√°gina y extraer informaci√≥n
    for page in doc:
        blocks = page.get_text("dict")["blocks"]
        for b in blocks:
            for l in b.get("lines", []):
                for span in l["spans"]:
                    text = span["text"].strip()
                    rgb = color_to_rgb(span["color"])
                    font = span["font"]
                    is_bold = "Bold" in font or "bold" in font.lower()

                    # Familia profesional (verde y may√∫sculas)
                    if text.isupper() and rgb[1] > 120 and rgb[0] < 100 and rgb[2] < 100:
                        familia_actual = text

                    # Grado formativo (naranja y may√∫sculas)
                    # elif text.isupper() and rgb[0] > 150 and rgb[1] > 90 and rgb[2] < 50:
                    #     grado_actual = text
                    elif rgb[0] > 150 and 90 < rgb[1] < 190 and rgb[2] > 80:
                        grado_actual = text  # Guardamos el texto literal como grado actual

                    # Ciclo formativo (azul, con c√≥digo entre par√©ntesis)
                    elif text.startswith("(") and ")" in text and rgb[2] > 100:
                        if ")" in text:
                            codigo_ciclo = text.split(")")[0].strip("()")
                            nombre_ciclo = text.split(")", 1)[1].strip()

                    # Provincia (negrita + negro)
                    elif text in ["BADAJOZ", "C√ÅCERES"] and is_bold:
                        provincia_actual = text

                    # Centro educativo (normal, negro, contiene ' - ' al menos 2 veces)
                    elif text.count(" - ") >= 2 and not is_bold and rgb == (0, 0, 0):
                        try:
                            municipio, instituto, curso_raw = text.split(" - ", 2)

                            # Extras
                            curso = curso_raw
                            turno = "Diurno"
                            bilingue = "No"
                            nuevo = "No"

                            if "Vespertino" in curso:
                                turno = "Vespertino"
                            if "Biling√ºe" in curso or "Bilingue" in curso:
                                bilingue = "S√≠"
                            if "Nuevo" in curso:
                                nuevo = "S√≠"

                            # Limpiar texto del campo curso
                            curso = (curso
                                    .replace("Vespertino", "")
                                    .replace("Diurno", "")
                                    .replace("Nuevo", "")
                                    .replace("Biling√ºe: IN", "")
                                    .strip())

                            # A√±adir fila
                            data.append({
                                "Familia Profesional": familia_actual,
                                "Grado": grado_actual,
                                "C√≥digo Ciclo": codigo_ciclo,
                                "Nombre Ciclo": nombre_ciclo,
                                "Provincia": provincia_actual,
                                "Municipio": municipio.strip(),
                                "Instituto": instituto.strip(),
                                "Curso": curso.strip(),
                                "Turno": turno,
                                "Biling√ºe": bilingue,
                                "Nuevo": nuevo
                            })

                        except ValueError:
                            continue  # l√≠nea malformada

    # Convertir a DataFrame
    df = pd.DataFrame(data)

    # Exportar a Excel
    df.to_excel(FileExcel, index=False)
    print("Fichero Excel creado : " + FileExcel)

    # Mostrar primeras filas
    #print(df.head())
    #df.head()

    return df

#--------------------------------------------------------------------

# Definici√≥n de rutas y ficheros de datos
url = "https://raw.githubusercontent.com/antoniojasweb/chatbot/main/pdf/"
FilePDF = "25_26_OFERTA_por_Familias.pdf"
FileExcel = "oferta_formativa_completa.xlsx"

if not os.path.exists(FilePDF):
    descargar_pdf(FilePDF)

if os.path.exists(FileExcel):
     os.remove(FileExcel)

#if not os.path.exists(FileExcel):
df = extraer_informacion_pdf(FilePDF)
df.head()

!pip install streamlit PyPDF2 spacy sentence-transformers scikit-learn
!python -m spacy download es_core_news_sm

import streamlit as st
import PyPDF2
import re
import spacy
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import json

# --- 1. Interfaz de Usuario con Streamlit ---
st.set_page_config(page_title="Chatbot de Asistencia Acad√©mica", page_icon="üéì")

st.title("üéì Chatbot de Asistencia Acad√©mica")
st.info("Soy un asistente experto en la oferta formativa de la Junta de Extremadura para el a√±o acad√©mico 2025/2026. Puedes preguntarme sobre cursos, niveles, ubicaciones o familias profesionales.")

# Inicializar historial de chat en el estado de sesi√≥n
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostrar mensajes del historial de chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Entrada de usuario
if prompt := st.chat_input("Hazme una pregunta sobre la oferta formativa..."):
    # A√±adir mensaje del usuario al historial
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("Buscando informaci√≥n..."):
            # 1. Recuperar informaci√≥n relevante
            context = rag_system.retrieve_information(prompt)

            # 2. Generar respuesta con el LLM (placeholder)
            response = rag_system.generate_response_with_llm(prompt, context)

            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})

# Opcional: Bot√≥n para limpiar el historial de chat
if st.sidebar.button("Limpiar Chat"):
    st.session_state.messages = []
    st.rerun()

#!streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py

#extracted_data =
#sample_courses_data =

# --- 2. Configuraci√≥n y Carga de Modelos ---
# Cargar el modelo de SpaCy para espa√±ol
try:
    nlp = spacy.load("es_core_news_sm")
except OSError:
    st.error("Modelo 'es_core_news_sm' de SpaCy no encontrado. Ejecuta: python -m spacy download es_core_news_sm")
    st.stop()

# Cargar el modelo de Sentence Transformer para embeddings
@st.cache_resource
def load_embedding_model():
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

embedding_model = load_embedding_model()

# --- 5. Representaci√≥n del Conocimiento (VECTOR_DB) ---
class VectorDatabase:
    def __init__(self, courses_df, embedding_model): # Changed parameter name to indicate DataFrame
        self.courses_df = courses_df # Store the DataFrame
        self.embedding_model = embedding_model
        self.course_texts = []
        # self.course_embeddings = [] # We will generate embeddings later
        self._build_index()

    def _build_index(self):
        """
        Crea los textos para indexar y sus embeddings.
        Combina varios campos para una representaci√≥n rica.
        """
        # Iterate over DataFrame rows and convert each row (Series) to a dictionary
        for index, course_series in self.courses_df.iterrows():
            course = course_series.to_dict() # Convert Series row to dictionary

            # Crear un texto descriptivo para cada curso para el embedding
            text_to_embed = (
                f"{course.get('Familia Profesional', '')} " # Use .get() for safety
                f"{course.get('Nombre Ciclo', '')} {course.get('C√≥digo Ciclo', '')} "
                f"{course.get('Grado', '')} {course.get('Instituto', '')} "
                f"{course.get('Municipio', '')} {course.get('Provincia', '')} "
                f"{course.get('Curso', '')} {course.get('Turno', '')} "
            )
            # Check for 'Biling√ºe' and 'Nuevo' using .get() as well
            if course.get('Biling√ºe', 'No') == 'S√≠':
                text_to_embed += " Biling√ºe"
            if course.get('Nuevo', 'No') == 'S√≠':
                text_to_embed += " Nuevo"

            self.course_texts.append(preprocess_text(text_to_embed.strip())) # Add strip to remove leading/trailing spaces

        # Generar embeddings en lotes para eficiencia after collecting all texts
        if self.course_texts: # Only encode if there are texts
             self.course_embeddings = self.embedding_model.encode(self.course_texts, show_progress_bar=False)
        else:
             self.course_embeddings = np.array([]) # Handle case with no data


    def search(self, query, top_k=5):
        """
        Busca los cursos m√°s relevantes para una consulta dada.
        """
        if not self.course_embeddings.size:
            return [] # Return empty list if no embeddings were created

        processed_query = preprocess_text(query)
        query_embedding = self.embedding_model.encode([processed_query])

        # Ensure query_embedding is 2D
        query_embedding = np.array(query_embedding)
        if query_embedding.ndim == 3:
            query_embedding = query_embedding.squeeze()
        if query_embedding.ndim == 1:
            query_embedding = query_embedding.reshape(1, -1)

        # Ensure course_embeddings is 2D
        # self.course_embeddings is already expected to be 2D after encoding
        # if self.course_embeddings.ndim == 3:
        #     self.course_embeddings = self.course_embeddings.squeeze()

        # Compute cosine similarity
        similarities = cosine_similarity(query_embedding, self.course_embeddings)

        # Get top_k indices. Use min(top_k, len(self.courses_df)) to avoid index errors
        top_k_actual = min(top_k, len(self.courses_df))
        top_indices = np.argsort(similarities)[0][::-1][:top_k_actual]

        results = []
        for idx in top_indices:
            results.append({
                "course": self.courses_df.iloc[idx].to_dict(), # Get the original row data as dictionary
                "similarity": similarities[0][idx]
            })
        return results

# Note: You will also need the preprocess_text function defined before this class.
# And the Course class (or similar structure) for the RAGSystem to use in retrieve_information.
# Based on the provided code snippet for RAGSystem, it looks like it expects a dictionary and then converts it to a Course object.

# Define a placeholder preprocess_text function if it's not defined elsewhere
def preprocess_text(text):
    # Basic preprocessing example: lowercase and remove some punctuation
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    return text

# Define a placeholder Course class based on how it's used in RAGSystem
class Course:
    def __init__(self, **kwargs):
        # Store all key-value pairs from the dictionary
        self.__dict__.update(kwargs)

    def __str__(self):
        # Create a string representation of the course
        # Use getattr to safely access attributes, providing a default empty string
        return (
            f"Familia Profesional: {getattr(self, 'Familia Profesional', 'N/A')}\n"
            f"Nombre Ciclo: {getattr(self, 'Nombre Ciclo', 'N/A')} ({getattr(self, 'C√≥digo Ciclo', 'N/A')})\n"
            f"Grado: {getattr(self, 'Grado', 'N/A')}\n"
            f"Instituto: {getattr(self, 'Instituto', 'N/A')}\n"
            f"Ubicaci√≥n: {getattr(self, 'Municipio', 'N/A')}, {getattr(self, 'Provincia', 'N/A')}\n"
            f"Curso: {getattr(self, 'Curso', 'N/A')}\n"
            f"Turno: {getattr(self, 'Turno', 'N/A')}\n"
            f"Biling√ºe: {getattr(self, 'Biling√ºe', 'No')}\n"
            f"Nuevo: {getattr(self, 'Nuevo', 'No')}"
        )


# Initialize the vector database with the DataFrame
vector_db = VectorDatabase(df, embedding_model)

# Initialize the RAG system with the vector database
#rag_system = RAGSystem(vector_db)

# --- 6. Sistema RAG (Generaci√≥n Aumentada por Recuperaci√≥n) ---
class RAGSystem:
    def __init__(self, vector_db):
        self.vector_db = vector_db

    def retrieve_information(self, query):
        """
        Recupera los documentos m√°s relevantes de la base de conocimiento.
        """
        # Aqu√≠ se podr√≠a a√±adir l√≥gica para filtrar por metadatos antes de la b√∫squeda sem√°ntica
        # Por ejemplo, si la consulta incluye "provincia: C√°ceres", filtrar primero por provincia.

        # Para este ejemplo, solo usamos la b√∫squeda sem√°ntica
        relevant_courses = self.vector_db.search(query, top_k=5)

        context = []
        for res in relevant_courses:
            course_obj = Course(**res['Curso'])
            context.append(str(course_obj))

        return "\n\n".join(context)

    def generate_response_with_llm(self, user_query, retrieved_context):
        """
        Genera una respuesta utilizando un LLM y el contexto recuperado.

        NOTA: Esta funci√≥n es un placeholder. Para una implementaci√≥n real,
        necesitar√≠as integrar un LLM (por ejemplo, OpenAI, Gemini, Hugging Face local)
        y usar tu clave API si es necesario.
        """
        if not retrieved_context:
            return "Lo siento, no pude encontrar informaci√≥n relevante en la oferta formativa para tu consulta."

        # Prompt engineering para guiar al LLM
        prompt = (
            "Eres un asistente experto en la oferta formativa de la Junta de Extremadura para el a√±o 2025/2026. "
            "Tu objetivo es proporcionar informaci√≥n precisa y concisa basada *exclusivamente* en el contexto proporcionado. "
            "Si la informaci√≥n no est√° en el contexto, indica que no puedes responder a esa pregunta. "
            "No alucines ni inventes informaci√≥n.\n\n"
            "Contexto de la oferta formativa:\n"
            f"{retrieved_context}\n\n"
            f"Pregunta del usuario: {user_query}\n\n"
            "Respuesta:"
        )

        # --- Placeholder para la llamada al LLM ---
        # Ejemplo de c√≥mo se har√≠a con un LLM real (requiere configuraci√≥n de API key)
        # from openai import OpenAI
        # client = OpenAI(api_key="TU_API_KEY")
        # response = client.chat.completions.create(
        #     model="gpt-3.5-turbo", # O el modelo que prefieras
        #     messages=[{"role": "user", "content": prompt}],
        #     temperature=0.1, # Baja temperatura para respuestas m√°s deterministas
        # ).choices.message.content
        # return response

        # Simulaci√≥n de respuesta del LLM basada en el contexto
        # En un LLM real, la respuesta ser√≠a m√°s elaborada y resumir√≠a el contexto.
        # Aqu√≠, simplemente devolvemos el contexto si es relevante.

        # L√≥gica simple para simular una respuesta basada en el contexto
        if "curso" in user_query.lower() or "formaci√≥n" in user_query.lower() or "programa" in user_query.lower():
            return f"Seg√∫n la oferta formativa, aqu√≠ tienes la informaci√≥n relevante:\n\n{retrieved_context}\n\n¬øHay algo m√°s en lo que pueda ayudarte?"
        elif "hola" in user_query.lower() or "saludo" in user_query.lower():
            return "¬°Hola! Soy tu asistente experto en la oferta formativa de la Junta de Extremadura. ¬øEn qu√© puedo ayudarte hoy?"
        else:
            return f"He encontrado la siguiente informaci√≥n relacionada con tu consulta:\n\n{retrieved_context}\n\nPor favor, especifica si necesitas m√°s detalles sobre alg√∫n curso o familia profesional."


rag_system = RAGSystem(vector_db)

# Opcional: Cargar PDF (solo para demostraci√≥n del parser conceptual)
# st.sidebar.header("Cargar PDF (Opcional)")
# uploaded_file = st.sidebar.file_uploader("Sube el archivo 'Oferta formativa. Mod. Presencial Completa 25/26.pdf'", type="pdf")
# if uploaded_file is not None:
#     st.sidebar.write("Archivo cargado. Procesando (esto puede tardar)...")
#     # Guardar el archivo temporalmente para PyPDF2
#     with open("temp_oferta.pdf", "wb") as f:
#         f.write(uploaded_file.getbuffer())
#
#     parsed_data = parse_pdf("temp_oferta.pdf")
#     if parsed_data:
#         st.sidebar.success(f"Se extrajeron {len(parsed_data)} entradas de cursos del PDF.")
#         # Aqu√≠ podr√≠as actualizar vector_db con los datos del PDF si el parsing fuera robusto
#         # vector_db = VectorDatabase(parsed_data, embedding_model)
#         # rag_system = RAGSystem(vector_db)
#         st.sidebar.json(parsed_data[:5]) # Mostrar las primeras 5 entradas
#     else:
#         st.sidebar.warning("No se pudo extraer informaci√≥n estructurada del PDF con el parser actual.")
